---
layout: post
date: 2025-05-12 16:09:30
title: "Conversational Interfaces"
description: "Why conversational interfaces still aren't the right approach for human-computer interaction."
img: /images/post-images/conversational-interfaces.jpg
categories: blog
tags:
- product
- design
- speech
- AI
- LLMs

links:
- url: https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/
  title: "The Case Against Conversational Interfaces"
  icon: 💬
---

Julian Lehr wrote an interesting post recently on the problems with conversational interfaces, with the fitting title "[The case against conversational
interfaces](https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/ "The case against conversational interfaces")". Here's Julian:

> We keep telling ourselves that previous voice interfaces like Alexa or Siri didn’t succeed because the underlying AI wasn’t smart enough, but that’s only half of the story. The core problem was never the quality of the output function, but the inconvenience of the input function: A natural language prompt like “Hey Google, what’s the weather in San Francisco today?” just takes 10x longer than simply tapping the weather app on your homescreen.

Voice works so well in human-to-human communication because it's enormously flexible on both ends — for speaker and listener. Through speech we can both communicate and understand just about any idea using the same framework of 26 letters and a couple thousand words.

The speaker can walk up to anyone fluent in the language and fairly effectively communicate just about anything — commands, requests, thoughts, ideas, emotions — and have the listener comprehend.

But conversation is slow. The "bitrate" for conversational speech is peanuts compared to what you can do with hand signals or ideograms or jpegs. A set of hand signals could convey a message much faster, but at the expense of loss of range, and easier misinterpretation. Spoken language trades bandwidth and information density for flexibility, nuance, and error tolerance. All major utilities when talking with a stranger, but not with our computers.

We keep chasing conversational interfaces in computing because of ease-of-access and the promise of flexibility. But in commanding the computer, the
loss of compression, low bandwidth, and ambiguity are annoyances rather than assets. When we have a conversation with a clerk at the store, these are
features. When it's with our computers, they feel like bugs.

Julian goes on to talk about how we might think more creatively with fitting LLMs into this picture:

> We spend too much time thinking about AI as a substitute (for interfaces, workflows, and jobs) and too little time about AI as a complement. Progress rarely follows a simple path of replacement. It unlocks new, previously unimaginable things rather than merely displacing what came before.

As AI seeps in everywhere, we need to think positive-sum in how it helps the human-computer interaction problem. It holds the potential to generate
background threads of activity as we're using our slow-but-flexible inputs like speech or typing: retrieving information and summarizing and
performing interstitial actions while we're in the middle of other tasks.
